{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4de0a2cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-17 00:22:00.737439: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1752682920.747379   33461 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1752682920.750439   33461 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1752682920.758736   33461 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1752682920.758768   33461 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1752682920.758769   33461 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1752682920.758771   33461 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用CPU加载SavedModel...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-17 00:22:02.056372: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型输入签名:\n",
      "  efficientnetb5_input: TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name='efficientnetb5_input')\n",
      "输入数据形状: (1, 224, 224, 3)\n",
      "Raw prediction output: [[0.41770187]]\n",
      "输出形状: (1, 1)\n",
      "Predicted class (0/1): [[0]]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# 完全禁用GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"  # 减少日志输出\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# 确保TensorFlow使用CPU\n",
    "tf.config.set_visible_devices([], 'GPU')\n",
    "\n",
    "def load_and_predict():\n",
    "    \"\"\"使用CPU进行SavedModel推理\"\"\"\n",
    "    try:\n",
    "        print(\"使用CPU加载SavedModel...\")\n",
    "        \n",
    "        # 加载SavedModel\n",
    "        model = tf.saved_model.load(\"./saved_model/saved_model_dir\")\n",
    "        \n",
    "        # 获取推理函数\n",
    "        infer = model.signatures[\"serving_default\"]\n",
    "        \n",
    "        # 检查输入签名\n",
    "        print(\"模型输入签名:\")\n",
    "        for key, spec in infer.structured_input_signature[1].items():\n",
    "            print(f\"  {key}: {spec}\")\n",
    "        \n",
    "        # 准备输入数据\n",
    "        test_image = np.random.rand(1, 224, 224, 3).astype(np.float32)\n",
    "        print(f\"输入数据形状: {test_image.shape}\")\n",
    "        \n",
    "        # 转换为tensor并指定设备\n",
    "        with tf.device('/CPU:0'):\n",
    "            input_tensor = tf.constant(test_image)\n",
    "            \n",
    "            # 进行预测\n",
    "            predictions = infer(input_tensor)\n",
    "        \n",
    "        # 获取输出\n",
    "        output_key = list(predictions.keys())[0]\n",
    "        result = predictions[output_key].numpy()\n",
    "        \n",
    "        print(\"Raw prediction output:\", result)\n",
    "        print(f\"输出形状: {result.shape}\")\n",
    "        \n",
    "        if result.shape[-1] == 1:\n",
    "            predicted_class = (result > 0.5).astype(int)\n",
    "            print(\"Predicted class (0/1):\", predicted_class)\n",
    "        else:\n",
    "            predicted_class = np.argmax(result, axis=-1)\n",
    "            print(\"Predicted class index:\", predicted_class)\n",
    "            \n",
    "        return result\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"预测失败: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "# 执行预测\n",
    "result = load_and_predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e3d4ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
